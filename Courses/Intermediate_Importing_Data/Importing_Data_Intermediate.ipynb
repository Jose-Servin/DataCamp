{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Importing flat files from the web"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from urllib.request import urlretrieve, urlopen, Request\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import tweepy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## The urllib package\n",
    "* Provides interface for fetching data across the web\n",
    "* urlopen() - accepts URL's instead of file names"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Importin files from web and saving locally"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "('winequality-white.csv', <http.client.HTTPMessage at 0x7ff3375feaf0>)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv'\n",
    "urlretrieve(url, 'winequality-white.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n0            7.0              0.27         0.36            20.7      0.045   \n1            6.3              0.30         0.34             1.6      0.049   \n2            8.1              0.28         0.40             6.9      0.050   \n3            7.2              0.23         0.32             8.5      0.058   \n4            7.2              0.23         0.32             8.5      0.058   \n\n   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n0                 45.0                 170.0   1.0010  3.00       0.45   \n1                 14.0                 132.0   0.9940  3.30       0.49   \n2                 30.0                  97.0   0.9951  3.26       0.44   \n3                 47.0                 186.0   0.9956  3.19       0.40   \n4                 47.0                 186.0   0.9956  3.19       0.40   \n\n   alcohol  quality  \n0      8.8        6  \n1      9.5        6  \n2     10.1        6  \n3      9.9        6  \n4      9.9        6  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fixed acidity</th>\n      <th>volatile acidity</th>\n      <th>citric acid</th>\n      <th>residual sugar</th>\n      <th>chlorides</th>\n      <th>free sulfur dioxide</th>\n      <th>total sulfur dioxide</th>\n      <th>density</th>\n      <th>pH</th>\n      <th>sulphates</th>\n      <th>alcohol</th>\n      <th>quality</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7.0</td>\n      <td>0.27</td>\n      <td>0.36</td>\n      <td>20.7</td>\n      <td>0.045</td>\n      <td>45.0</td>\n      <td>170.0</td>\n      <td>1.0010</td>\n      <td>3.00</td>\n      <td>0.45</td>\n      <td>8.8</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>6.3</td>\n      <td>0.30</td>\n      <td>0.34</td>\n      <td>1.6</td>\n      <td>0.049</td>\n      <td>14.0</td>\n      <td>132.0</td>\n      <td>0.9940</td>\n      <td>3.30</td>\n      <td>0.49</td>\n      <td>9.5</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8.1</td>\n      <td>0.28</td>\n      <td>0.40</td>\n      <td>6.9</td>\n      <td>0.050</td>\n      <td>30.0</td>\n      <td>97.0</td>\n      <td>0.9951</td>\n      <td>3.26</td>\n      <td>0.44</td>\n      <td>10.1</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>7.2</td>\n      <td>0.23</td>\n      <td>0.32</td>\n      <td>8.5</td>\n      <td>0.058</td>\n      <td>47.0</td>\n      <td>186.0</td>\n      <td>0.9956</td>\n      <td>3.19</td>\n      <td>0.40</td>\n      <td>9.9</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7.2</td>\n      <td>0.23</td>\n      <td>0.32</td>\n      <td>8.5</td>\n      <td>0.058</td>\n      <td>47.0</td>\n      <td>186.0</td>\n      <td>0.9956</td>\n      <td>3.19</td>\n      <td>0.40</td>\n      <td>9.9</td>\n      <td>6</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('winequality-white.csv', sep=';')\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Importing files from web without saving locally"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n0            7.4              0.70         0.00             1.9      0.076   \n1            7.8              0.88         0.00             2.6      0.098   \n2            7.8              0.76         0.04             2.3      0.092   \n3           11.2              0.28         0.56             1.9      0.075   \n4            7.4              0.70         0.00             1.9      0.076   \n\n   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n0                 11.0                  34.0   0.9978  3.51       0.56   \n1                 25.0                  67.0   0.9968  3.20       0.68   \n2                 15.0                  54.0   0.9970  3.26       0.65   \n3                 17.0                  60.0   0.9980  3.16       0.58   \n4                 11.0                  34.0   0.9978  3.51       0.56   \n\n   alcohol  quality  \n0      9.4        5  \n1      9.8        5  \n2      9.8        5  \n3      9.8        6  \n4      9.4        5  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fixed acidity</th>\n      <th>volatile acidity</th>\n      <th>citric acid</th>\n      <th>residual sugar</th>\n      <th>chlorides</th>\n      <th>free sulfur dioxide</th>\n      <th>total sulfur dioxide</th>\n      <th>density</th>\n      <th>pH</th>\n      <th>sulphates</th>\n      <th>alcohol</th>\n      <th>quality</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7.4</td>\n      <td>0.70</td>\n      <td>0.00</td>\n      <td>1.9</td>\n      <td>0.076</td>\n      <td>11.0</td>\n      <td>34.0</td>\n      <td>0.9978</td>\n      <td>3.51</td>\n      <td>0.56</td>\n      <td>9.4</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7.8</td>\n      <td>0.88</td>\n      <td>0.00</td>\n      <td>2.6</td>\n      <td>0.098</td>\n      <td>25.0</td>\n      <td>67.0</td>\n      <td>0.9968</td>\n      <td>3.20</td>\n      <td>0.68</td>\n      <td>9.8</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7.8</td>\n      <td>0.76</td>\n      <td>0.04</td>\n      <td>2.3</td>\n      <td>0.092</td>\n      <td>15.0</td>\n      <td>54.0</td>\n      <td>0.9970</td>\n      <td>3.26</td>\n      <td>0.65</td>\n      <td>9.8</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>11.2</td>\n      <td>0.28</td>\n      <td>0.56</td>\n      <td>1.9</td>\n      <td>0.075</td>\n      <td>17.0</td>\n      <td>60.0</td>\n      <td>0.9980</td>\n      <td>3.16</td>\n      <td>0.58</td>\n      <td>9.8</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7.4</td>\n      <td>0.70</td>\n      <td>0.00</td>\n      <td>1.9</td>\n      <td>0.076</td>\n      <td>11.0</td>\n      <td>34.0</td>\n      <td>0.9978</td>\n      <td>3.51</td>\n      <td>0.56</td>\n      <td>9.4</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url  = 'http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv'\n",
    "df_not_saved_locally = pd.read_csv(url, sep= ';')\n",
    "df_not_saved_locally.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Importing non-flat files from the web"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "dict_keys(['1700', '1900'])"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'http://s3.amazonaws.com/assets.datacamp.com/course/importing_data_into_r/latitude.xls'\n",
    "xls = pd.read_excel(url, sheet_name=None)\n",
    "xls.keys()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "                 country       1700\n0            Afghanistan  34.565000\n1  Akrotiri and Dhekelia  34.616667\n2                Albania  41.312000\n3                Algeria  36.720000\n4         American Samoa -14.307000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>country</th>\n      <th>1700</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Afghanistan</td>\n      <td>34.565000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Akrotiri and Dhekelia</td>\n      <td>34.616667</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Albania</td>\n      <td>41.312000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Algeria</td>\n      <td>36.720000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>American Samoa</td>\n      <td>-14.307000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xls['1700'].head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# HTTP request to import files from the web"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## GET requests using urllib"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "url = 'https://www.wikipedia.org/'\n",
    "request = Request(url) # Package GET request using Request function\n",
    "response = urlopen(request) # send GET request and catch response using urlopen(); returns HTTP response object which has a read method\n",
    "html = response.read() # apply read() method to response to get html as string\n",
    "response.close() # close response"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## GET requests using Requests package"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "url = 'https://www.wikipedia.org/'\n",
    "r = requests.get(url) # package request, send request and catch response with a single function\n",
    "text = r.text # returns HTML as string by applying .text method"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Scraping the web in Python"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## BeautifulSoup"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.0 Transitional//EN\"\n\"http://www.w3.org/TR/REC-html40/transitional.dtd\">\n\n<html>\n<head>\n<meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-Type\"/>\n<title>Beautiful Soup: We called him Tortoise because he taught us.</title>\n<link href=\"mailto:leonardr@segfault.org\" rev=\"made\"/>\n<link href=\"/nb/themes/Default/nb.css\" rel=\"stylesheet\" type=\"text/css\"/>\n<meta content=\"Beautiful Soup: a library designed for screen-scraping HTML and XML.\" name=\"Description\"/>\n<meta content=\"Markov Approximation 1.4 (module: leonardr)\" name=\"generator\"/>\n<meta content=\"Leonard Richardson\" name=\"author\"/>\n</head>\n<body alink=\"red\" bgcolor=\"white\" link=\"blue\" text=\"black\" vlink=\"660066\">\n<style>\n#tidelift { }\n\n#tidelift a {\n border: 1px solid #666666;\n margin-left: auto;\n padding: 10px;\n text-decoration: none;\n}\n\n#tidelift .cta {\n background: url(\"tidelift.svg\") no-repeat;\n padding-left: 30px;\n}\n</style>\n<img align=\"right\" src=\"10.1.jpg\" width=\"250\"/><br/>\n<p>[ <a href=\"#Download\">Download</a> | <a href=\"bs4/doc/\">Documentation</a> | <a href=\"#HallOfFame\">Hall of Fame</a> | <a href=\"enterprise.html\">For enterprise</a> | <a href=\"https://code.launchpad.net/beautifulsoup\">Source</a> | <a href=\"https://bazaar.launchpad.net/%7Eleonardr/beautifulsoup/bs4/view/head:/CHANGELOG\">Changelog</a> | <a href=\"https://groups.google.com/forum/?fromgroups#!forum/beautifulsoup\">Discussion group</a>  | <a href=\"zine/\">Zine</a> ]</p>\n<div align=\"center\">\n<a href=\"bs4/download/\"><h1>Beautiful Soup</h1></a>\n</div>\n<p>You didn't write that awful page. You're just trying to get some\ndata out of it. Beautiful Soup is here to help. Since 2004, it's been\nsaving programmers hours or days of work on quick-turnaround\nscreen scraping projects.</p>\n<p>Beautiful Soup is a Python library designed for quick turnaround\nprojects like screen-scraping. Three features make it powerful:\n\n<ol>\n<li>Beautiful Soup provides a few simple methods and Pythonic idioms\nfor navigating, searching, and modifying a parse tree: a toolkit for\ndissecting a document and extracting what you need. It doesn't take\nmuch code to write an application\n\n<li>Beautiful Soup automatically converts incoming documents to\nUnicode and outgoing documents to UTF-8. You don't have to think\nabout encodings, unless the document doesn't specify an encoding and\nBeautiful Soup can't detect one. Then you just have to specify the\noriginal encoding.\n\n<li>Beautiful Soup sits on top of popular Python parsers like <a href=\"http://lxml.de/\">lxml</a> and <a href=\"http://code.google.com/p/html5lib/\">html5lib</a>, allowing you\nto try out different parsing strategies or trade speed for\nflexibility.\n\n</li></li></li></ol>\n<p>Beautiful Soup parses anything you give it, and does the tree\ntraversal stuff for you. You can tell it \"Find all the links\", or\n\"Find all the links of class <tt>externalLink</tt>\", or \"Find all the\nlinks whose urls match \"foo.com\", or \"Find the table heading that's\ngot bold text, then give me that text.\"\n\n<p>Valuable data that was once locked up in poorly-designed websites\nis now within your reach. Projects that would have taken hours take\nonly minutes with Beautiful Soup.\n\n<p>Interested? <a href=\"bs4/doc/\">Read more.</a>\n<h3>Getting and giving support</h3>\n<div align=\"center\" id=\"tidelift\">\n<a href=\"https://tidelift.com/subscription/pkg/pypi-beautifulsoup4?utm_source=pypi-beautifulsoup4&amp;utm_medium=referral&amp;utm_campaign=enterprise\" target=\"_blank\">\n<span class=\"cta\">\n  Beautiful Soup for enterprise available via Tidelift\n </span>\n</a>\n</div>\n<p>If you have questions, send them to <a href=\"https://groups.google.com/forum/?fromgroups#!forum/beautifulsoup\">the discussion\ngroup</a>. If you find a bug, <a href=\"https://bugs.launchpad.net/beautifulsoup/\">file it on Launchpad</a>. If it's a security vulnerability, report it confidentially through <a href=\"https://tidelift.com/security\">Tidelift</a>.</p>\n<p>If you use Beautiful Soup as part of your work, please consider a <a href=\"https://tidelift.com/subscription/pkg/pypi-beautifulsoup4?utm_source=pypi-beautifulsoup4&amp;utm_medium=referral&amp;utm_campaign=website\">Tidelift subscription</a>. This will support many of the free software projects your organization depends on, not just Beautiful Soup.\n\n\n<p>If Beautiful Soup is useful to you on a personal level, you might like to read <a href=\"zine/\"><i>Tool Safety</i></a>, a short zine I wrote about what I learned about software development from working on Beautiful Soup. Thanks!</p>\n\n<a name=\"Download\"><h2>Download Beautiful Soup</h2></a>\n<p>The current release is <a href=\"bs4/download/\">Beautiful Soup\n4.10.0</a> (September 7, 2021). You can install Beautiful Soup 4 with\n<code>pip install beautifulsoup4</code>.\n\n<p>In Debian and Ubuntu, Beautiful Soup is available as the\n<code>python-bs4</code> package (for Python 2) or the\n<code>python3-bs4</code> package (for Python 3). In Fedora it's\navailable as the <code>python-beautifulsoup4</code> package.\n\n<p>Beautiful Soup is licensed under the MIT license, so you can also\ndownload the tarball, drop the <code>bs4/</code> directory into almost\nany Python application (or into your library path) and start using it\nimmediately. (If you want to do this under Python 3, you will need to\nmanually convert the code using <code>2to3</code>.)\n\n<p>Beautiful Soup 4 works on both Python 2 (2.7+) and Python\n3. Support for Python 2 will be discontinued on or after December 31,\n2020—one year after the Python 2 sunsetting date.\n\n<h3>Beautiful Soup 3</h3>\n<p>Beautiful Soup 3 was the official release line of Beautiful Soup\nfrom May 2006 to March 2012. It does not support Python 3 and it will\nbe discontinued on or after December 31, 2020—one year after the\nPython 2 sunsetting date. If you have any active projects using\nBeautiful Soup 3, you should migrate to Beautiful Soup 4 as part of\nyour Python 3 conversion.\n\n<p><a href=\"http://www.crummy.com/software/BeautifulSoup/bs3/documentation.html\">Here's\nthe Beautiful Soup 3 documentation.</a>\n<p>The current and hopefully final release of Beautiful Soup 3 is <a href=\"download/3.x/BeautifulSoup-3.2.2.tar.gz\">3.2.2</a> (October 5,\n2019). It's the <code>BeautifulSoup</code> package on pip. It's also\navailable as <code>python-beautifulsoup</code> in Debian and Ubuntu,\nand as <code>python-BeautifulSoup</code> in Fedora.\n\n<p>Once Beautiful Soup 3 is discontinued, these package names will be available for use by a more recent version of Beautiful Soup.\n\n<p>Beautiful Soup 3, like Beautiful Soup 4, is <a href=\"https://tidelift.com/subscription/pkg/pypi-beautifulsoup?utm_source=pypi-beautifulsoup&amp;utm_medium=referral&amp;utm_campaign=website\">supported through Tidelift</a>.</p>\n<a name=\"HallOfFame\"><h2>Hall of Fame</h2></a>\n<p>Over the years, Beautiful Soup has been used in hundreds of\ndifferent projects. There's no way I can list them all, but I want to\nhighlight a few high-profile projects. Beautiful Soup isn't what makes\nthese projects interesting, but it did make their completion easier:\n\n<ul>\n<li><a href=\"http://www.nytimes.com/2007/10/25/arts/design/25vide.html\">\"Movable\n Type\"</a>, a work of digital art on display in the lobby of the New\n York Times building, uses Beautiful Soup to scrape news feeds.\n\n<li>Jiabao Lin's <a href=\"https://github.com/BlankerL/DXY-COVID-19-Crawler\">DXY-COVID-19-Crawler</a>\nuses Beautiful Soup to scrape a Chinese medical site for information\nabout COVID-19, making it easier for researchers to track the spread\nof the virus. (Source: <a href=\"https://blog.tidelift.com/how-open-source-software-is-fighting-covid-19\">\"How open source software is fighting COVID-19\"</a>)\n\n<li>Reddit uses Beautiful Soup to <a href=\"https://github.com/reddit/reddit/blob/85f9cff3e2ab9bb8f19b96acd8da4ebacc079f04/r2/r2/lib/media.py\">parse\na page that's been linked to and find a representative image</a>.\n\n<li>Alexander Harrowell uses Beautiful Soup to <a href=\"http://www.harrowell.org.uk/viktormap.html\">track the business\n activities</a> of an arms merchant.\n\n<li>The developers of Python itself used Beautiful Soup to <a href=\"http://svn.python.org/view/tracker/importer/\">migrate the Python\nbug tracker from Sourceforge to Roundup</a>.\n\n<li>The <a href=\"http://www2.ljworld.com/\">Lawrence Journal-World</a>\nuses Beautiful Soup to <a href=\"http://www.b-list.org/weblog/2010/nov/02/news-done-broke/\">gather\nstatewide election results</a>.\n\n<li>The <a href=\"http://esrl.noaa.gov/gsd/fab/\">NOAA's Forecast\nApplications Branch</a> uses Beautiful Soup in <a href=\"http://laps.noaa.gov/topograbber/\">TopoGrabber</a>, a script for\ndownloading \"high resolution USGS datasets.\"\n\n</li></li></li></li></li></li></li></ul>\n<p>If you've used Beautiful Soup in a project you'd like me to know\nabout, please do send email to me or <a href=\"http://groups.google.com/group/beautifulsoup/\">the discussion\ngroup</a>.\n\n<h2>Development</h2>\n<p>Development happens at <a href=\"https://launchpad.net/beautifulsoup\">Launchpad</a>. You can <a href=\"https://code.launchpad.net/beautifulsoup/\">get the source\ncode</a> or <a href=\"https://bugs.launchpad.net/beautifulsoup/\">file\nbugs</a>.<hr/><table><tr><td valign=\"top\">\n<p>This document (<a href=\"/source/software/BeautifulSoup/index.bhtml\">source</a>) is part of Crummy, the webspace of <a href=\"/self/\">Leonard Richardson</a> (<a href=\"/self/contact.html\">contact information</a>). It was last modified on Wednesday, December 08 2021, 21:41:28 Nowhere Standard Time and last built on Wednesday, February 16 2022, 03:00:01 Nowhere Standard Time.</p><p><table class=\"licenseText\"><tr><td><a href=\"http://creativecommons.org/licenses/by-sa/2.0/\"><img border=\"0\" src=\"/nb//resources/img/somerights20.jpg\"/></a></td><td valign=\"top\">Crummy is © 1996-2022 Leonard Richardson. Unless otherwise noted, all text licensed under a <a href=\"http://creativecommons.org/licenses/by-sa/2.0/\">Creative Commons License</a>.</td></tr></table><!--<rdf:RDF xmlns=\"http://web.resource.org/cc/\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\"><Work rdf:about=\"http://www.crummy.com/\"><dc:title>Crummy: The Site</dc:title><dc:rights><Agent><dc:title>Crummy: the Site</dc:title></Agent></dc:rights><dc:format>text/html</dc:format><license rdf:resource=http://creativecommons.org/licenses/by-sa/2.0//></Work><License rdf:about=\"http://creativecommons.org/licenses/by-sa/2.0/\"></License></rdf:RDF>--></p></td><td valign=\"top\"><p><b>Document tree:</b>\n<dl><dd><a href=\"http://www.crummy.com/\">http://www.crummy.com/</a><dl><dd><a href=\"http://www.crummy.com/software/\">software/</a><dl><dd><a href=\"http://www.crummy.com/software/BeautifulSoup/\">BeautifulSoup/</a></dd></dl>\n</dd></dl>\n</dd></dl>\n\n\nSite Search:\n\n<form action=\"/search/\" method=\"get\">\n<input maxlength=\"255\" name=\"q\" type=\"text\" value=\"\"/>\n</form>\n</p></td>\n</tr>\n</table>\n</p></p></p></p></p></p></p></p></p></p></p></p></p></p></p></p></body>\n</html>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://www.crummy.com/software/BeautifulSoup/' # assign URL\n",
    "r = requests.get(url) # package request to URL, send request and catch response\n",
    "html_doc = r.text # use text attribute on object to return the HTML of the webpage as a string\n",
    "soup = BeautifulSoup(html_doc) # create BeautifulSoup object\n",
    "soup\n",
    "#pretty_soup = soup.prettify()\n",
    "#pretty_soup"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Getting the title from webpage\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "<title>Beautiful Soup: We called him Tortoise because he taught us.</title>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "webpage_title = soup.title\n",
    "webpage_title"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Getting the text from webpage"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "'\\n\\n\\n\\nBeautiful Soup: We called him Tortoise because he taught us.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n[ Download | Documentation | Hall of Fame | For enterprise | Source | Changelog | Discussion group  | Zine ]\\n\\nBeautiful Soup\\n\\nYou didn\\'t write that awful page. You\\'re just trying to get some\\ndata out of it. Beautiful Soup is here to help. Since 2004, it\\'s been\\nsaving programmers hours or days of work on quick-turnaround\\nscreen scraping projects.\\nBeautiful Soup is a Python library designed for quick turnaround\\nprojects like screen-scraping. Three features make it powerful:\\n\\n\\nBeautiful Soup provides a few simple methods and Pythonic idioms\\nfor navigating, searching, and modifying a parse tree: a toolkit for\\ndissecting a document and extracting what you need. It doesn\\'t take\\nmuch code to write an application\\n\\nBeautiful Soup automatically converts incoming documents to\\nUnicode and outgoing documents to UTF-8. You don\\'t have to think\\nabout encodings, unless the document doesn\\'t specify an encoding and\\nBeautiful Soup can\\'t detect one. Then you just have to specify the\\noriginal encoding.\\n\\nBeautiful Soup sits on top of popular Python parsers like lxml and html5lib, allowing you\\nto try out different parsing strategies or trade speed for\\nflexibility.\\n\\n\\nBeautiful Soup parses anything you give it, and does the tree\\ntraversal stuff for you. You can tell it \"Find all the links\", or\\n\"Find all the links of class externalLink\", or \"Find all the\\nlinks whose urls match \"foo.com\", or \"Find the table heading that\\'s\\ngot bold text, then give me that text.\"\\n\\nValuable data that was once locked up in poorly-designed websites\\nis now within your reach. Projects that would have taken hours take\\nonly minutes with Beautiful Soup.\\n\\nInterested? Read more.\\nGetting and giving support\\n\\n\\n\\n  Beautiful Soup for enterprise available via Tidelift\\n \\n\\n\\nIf you have questions, send them to the discussion\\ngroup. If you find a bug, file it on Launchpad. If it\\'s a security vulnerability, report it confidentially through Tidelift.\\nIf you use Beautiful Soup as part of your work, please consider a Tidelift subscription. This will support many of the free software projects your organization depends on, not just Beautiful Soup.\\n\\n\\nIf Beautiful Soup is useful to you on a personal level, you might like to read Tool Safety, a short zine I wrote about what I learned about software development from working on Beautiful Soup. Thanks!\\n\\nDownload Beautiful Soup\\nThe current release is Beautiful Soup\\n4.10.0 (September 7, 2021). You can install Beautiful Soup 4 with\\npip install beautifulsoup4.\\n\\nIn Debian and Ubuntu, Beautiful Soup is available as the\\npython-bs4 package (for Python 2) or the\\npython3-bs4 package (for Python 3). In Fedora it\\'s\\navailable as the python-beautifulsoup4 package.\\n\\nBeautiful Soup is licensed under the MIT license, so you can also\\ndownload the tarball, drop the bs4/ directory into almost\\nany Python application (or into your library path) and start using it\\nimmediately. (If you want to do this under Python 3, you will need to\\nmanually convert the code using 2to3.)\\n\\nBeautiful Soup 4 works on both Python 2 (2.7+) and Python\\n3. Support for Python 2 will be discontinued on or after December 31,\\n2020—one year after the Python 2 sunsetting date.\\n\\nBeautiful Soup 3\\nBeautiful Soup 3 was the official release line of Beautiful Soup\\nfrom May 2006 to March 2012. It does not support Python 3 and it will\\nbe discontinued on or after December 31, 2020—one year after the\\nPython 2 sunsetting date. If you have any active projects using\\nBeautiful Soup 3, you should migrate to Beautiful Soup 4 as part of\\nyour Python 3 conversion.\\n\\nHere\\'s\\nthe Beautiful Soup 3 documentation.\\nThe current and hopefully final release of Beautiful Soup 3 is 3.2.2 (October 5,\\n2019). It\\'s the BeautifulSoup package on pip. It\\'s also\\navailable as python-beautifulsoup in Debian and Ubuntu,\\nand as python-BeautifulSoup in Fedora.\\n\\nOnce Beautiful Soup 3 is discontinued, these package names will be available for use by a more recent version of Beautiful Soup.\\n\\nBeautiful Soup 3, like Beautiful Soup 4, is supported through Tidelift.\\nHall of Fame\\nOver the years, Beautiful Soup has been used in hundreds of\\ndifferent projects. There\\'s no way I can list them all, but I want to\\nhighlight a few high-profile projects. Beautiful Soup isn\\'t what makes\\nthese projects interesting, but it did make their completion easier:\\n\\n\\n\"Movable\\n Type\", a work of digital art on display in the lobby of the New\\n York Times building, uses Beautiful Soup to scrape news feeds.\\n\\nJiabao Lin\\'s DXY-COVID-19-Crawler\\nuses Beautiful Soup to scrape a Chinese medical site for information\\nabout COVID-19, making it easier for researchers to track the spread\\nof the virus. (Source: \"How open source software is fighting COVID-19\")\\n\\nReddit uses Beautiful Soup to parse\\na page that\\'s been linked to and find a representative image.\\n\\nAlexander Harrowell uses Beautiful Soup to track the business\\n activities of an arms merchant.\\n\\nThe developers of Python itself used Beautiful Soup to migrate the Python\\nbug tracker from Sourceforge to Roundup.\\n\\nThe Lawrence Journal-World\\nuses Beautiful Soup to gather\\nstatewide election results.\\n\\nThe NOAA\\'s Forecast\\nApplications Branch uses Beautiful Soup in TopoGrabber, a script for\\ndownloading \"high resolution USGS datasets.\"\\n\\n\\nIf you\\'ve used Beautiful Soup in a project you\\'d like me to know\\nabout, please do send email to me or the discussion\\ngroup.\\n\\nDevelopment\\nDevelopment happens at Launchpad. You can get the source\\ncode or file\\nbugs.\\nThis document (source) is part of Crummy, the webspace of Leonard Richardson (contact information). It was last modified on Wednesday, December 08 2021, 21:41:28 Nowhere Standard Time and last built on Wednesday, February 16 2022, 03:00:01 Nowhere Standard Time.Crummy is © 1996-2022 Leonard Richardson. Unless otherwise noted, all text licensed under a Creative Commons License.Document tree:\\nhttp://www.crummy.com/software/BeautifulSoup/\\n\\n\\n\\n\\nSite Search:\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "webpage_text = soup.get_text()\n",
    "webpage_text"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Getting the hyperlinks"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Download\n",
      "bs4/doc/\n",
      "#HallOfFame\n",
      "enterprise.html\n",
      "https://code.launchpad.net/beautifulsoup\n",
      "https://bazaar.launchpad.net/%7Eleonardr/beautifulsoup/bs4/view/head:/CHANGELOG\n",
      "https://groups.google.com/forum/?fromgroups#!forum/beautifulsoup\n",
      "zine/\n",
      "bs4/download/\n",
      "http://lxml.de/\n",
      "http://code.google.com/p/html5lib/\n",
      "bs4/doc/\n",
      "https://tidelift.com/subscription/pkg/pypi-beautifulsoup4?utm_source=pypi-beautifulsoup4&utm_medium=referral&utm_campaign=enterprise\n",
      "https://groups.google.com/forum/?fromgroups#!forum/beautifulsoup\n",
      "https://bugs.launchpad.net/beautifulsoup/\n",
      "https://tidelift.com/security\n",
      "https://tidelift.com/subscription/pkg/pypi-beautifulsoup4?utm_source=pypi-beautifulsoup4&utm_medium=referral&utm_campaign=website\n",
      "zine/\n",
      "None\n",
      "bs4/download/\n",
      "http://www.crummy.com/software/BeautifulSoup/bs3/documentation.html\n",
      "download/3.x/BeautifulSoup-3.2.2.tar.gz\n",
      "https://tidelift.com/subscription/pkg/pypi-beautifulsoup?utm_source=pypi-beautifulsoup&utm_medium=referral&utm_campaign=website\n",
      "None\n",
      "http://www.nytimes.com/2007/10/25/arts/design/25vide.html\n",
      "https://github.com/BlankerL/DXY-COVID-19-Crawler\n",
      "https://blog.tidelift.com/how-open-source-software-is-fighting-covid-19\n",
      "https://github.com/reddit/reddit/blob/85f9cff3e2ab9bb8f19b96acd8da4ebacc079f04/r2/r2/lib/media.py\n",
      "http://www.harrowell.org.uk/viktormap.html\n",
      "http://svn.python.org/view/tracker/importer/\n",
      "http://www2.ljworld.com/\n",
      "http://www.b-list.org/weblog/2010/nov/02/news-done-broke/\n",
      "http://esrl.noaa.gov/gsd/fab/\n",
      "http://laps.noaa.gov/topograbber/\n",
      "http://groups.google.com/group/beautifulsoup/\n",
      "https://launchpad.net/beautifulsoup\n",
      "https://code.launchpad.net/beautifulsoup/\n",
      "https://bugs.launchpad.net/beautifulsoup/\n",
      "/source/software/BeautifulSoup/index.bhtml\n",
      "/self/\n",
      "/self/contact.html\n",
      "http://creativecommons.org/licenses/by-sa/2.0/\n",
      "http://creativecommons.org/licenses/by-sa/2.0/\n",
      "http://www.crummy.com/\n",
      "http://www.crummy.com/software/\n",
      "http://www.crummy.com/software/BeautifulSoup/\n"
     ]
    }
   ],
   "source": [
    "a_tags = soup.find_all('a') # passing the HTML tag we want to find to find_all() method\n",
    "for link in a_tags:\n",
    "    print(link.get('href')) # print the actual URL's for the hyperlinks"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Intro to APIs and JSONs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "* API: Application Programming Interface\n",
    "* APIs are used for building and interacting with software applications"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading JSONs in Python"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "with open('/Users/joseservin/DataCamp/Courses/Intermediate_Importing_Data/json_ex.json', 'r') as json_file:\n",
    "    json_data = json.load(json_file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "dict"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(json_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exploring JSONs in Python"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name:John\n",
      "age:30\n",
      "car:None\n"
     ]
    }
   ],
   "source": [
    "for key, value in json_data.items():\n",
    "    print(key + \":\" + str(value))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Connecting to an API in Python"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "* APIs allow softwares to communicate with each other"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Process"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "* define URL variable\n",
    "* Package and send URL query and save to response variable\n",
    "* use .json() method on response variable to return dictionary\n",
    "* explore json"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title:Joker\n",
      "Year:2019\n",
      "Rated:R\n",
      "Released:04 Oct 2019\n",
      "Runtime:122 min\n",
      "Genre:Crime, Drama, Thriller\n",
      "Director:Todd Phillips\n",
      "Writer:Todd Phillips, Scott Silver, Bob Kane\n",
      "Actors:Joaquin Phoenix, Robert De Niro, Zazie Beetz\n",
      "Plot:In Gotham City, mentally troubled comedian Arthur Fleck is disregarded and mistreated by society. He then embarks on a downward spiral of revolution and bloody crime. This path brings him face-to-face with his alter-ego: the Joker.\n",
      "Language:English\n",
      "Country:United States, Canada\n",
      "Awards:Won 2 Oscars. 122 wins & 240 nominations total\n",
      "Poster:https://m.media-amazon.com/images/M/MV5BNGVjNWI4ZGUtNzE0MS00YTJmLWE0ZDctN2ZiYTk2YmI3NTYyXkEyXkFqcGdeQXVyMTkxNjUyNQ@@._V1_SX300.jpg\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"list\") to str",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [17]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      3\u001B[0m json_data \u001B[38;5;241m=\u001B[39m r\u001B[38;5;241m.\u001B[39mjson()\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m key, value \u001B[38;5;129;01min\u001B[39;00m json_data\u001B[38;5;241m.\u001B[39mitems():\n\u001B[0;32m----> 5\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[43mkey\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m:\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m)\n",
      "\u001B[0;31mTypeError\u001B[0m: can only concatenate str (not \"list\") to str"
     ]
    }
   ],
   "source": [
    "url = \"http://www.omdbapi.com/?t=Joker&apikey=3628e5f1\" #?t=hackers is called the Query string\n",
    "r = requests.get(url)\n",
    "json_data = r.json()\n",
    "for key, value in json_data.items():\n",
    "    print(key + \":\" + value)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exploring the Wikipedia API"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "url = 'https://en.wikipedia.org/w/api.php?action=query&prop=extracts&format=json&exintro=&titles=pizza'\n",
    "r = requests.get(url)\n",
    "json_data = r.json()\n",
    "for key in json_data.keys():\n",
    "    print(key)\n",
    "json_data['query']['pages']['24768']['extract']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# The Twitter API and authentication"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "* 1640014718-ywUwnpfPENiOZLKjJkjRg1WbYISyIh13Vb6j38f (access token)\n",
    "* 6iiqXDteEzBbl6LuYgJpQdNnv15KXdxOTcfoWfzY82MpO (access token secret)\n",
    "* ej89OqxCl3vAYd7OPdCYKI45z (API consumer key)\n",
    "* Yga9J9ODeXXLmIlMsmS3dqmQCMF3drABdI0nLmWbmfudn6Y9Z7 (API consumer secret)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}